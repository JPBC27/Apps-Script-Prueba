{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JPBC27/Apps-Script-Prueba/blob/main/Proceso_Eval_Desempe%C3%B1o_SPSA_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkGIIJ6FGJUS",
        "outputId": "14ef40ff-3ff3-44f3-9db1-428408418530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archivos en la carpeta:\n",
            "Base GOR GOS.xlsx\n",
            "6.- Estructura de personal - Colaboradores FRET + FREG + PVO + Makro + CHD + Oslo 31.01.xlsx\n",
            "closing_survey_monitoring__2025-01-31_10_12_15_-0300.xlsx\n",
            "evaluation_monitoring__2025-01-31_10_12_06_-0300.xlsx\n",
            "7.- Estructura de personal - Digital Foods 29.01.xlsx\n",
            "La carpeta '/content/drive/MyDrive/SPSA/Prueba Eval Desempeño/Inputs/Inputs Historico/2025-01-31' ya existe.\n",
            "Archivo '6.- Estructura de personal - Colaboradores FRET + FREG + PVO + Makro + CHD + Oslo 31.01.xlsx' copiado a '/content/drive/MyDrive/SPSA/Prueba Eval Desempeño/Inputs/Inputs Historico/2025-01-31'\n",
            "Archivo 'evaluation_monitoring__2025-01-31_10_12_06_-0300.xlsx' copiado a '/content/drive/MyDrive/SPSA/Prueba Eval Desempeño/Inputs/Inputs Historico/2025-01-31'\n",
            "Archivo 'closing_survey_monitoring__2025-01-31_10_12_15_-0300.xlsx' copiado a '/content/drive/MyDrive/SPSA/Prueba Eval Desempeño/Inputs/Inputs Historico/2025-01-31'\n",
            "Archivo '7.- Estructura de personal - Digital Foods 29.01.xlsx' copiado a '/content/drive/MyDrive/SPSA/Prueba Eval Desempeño/Inputs/Inputs Historico/2025-01-31'\n",
            "Archivo 'Base GOR GOS.xlsx' copiado a '/content/drive/MyDrive/SPSA/Prueba Eval Desempeño/Inputs/Inputs Historico/2025-01-31'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-bfa305ef1fdd>:99: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_base.drop_duplicates(inplace=True)\n",
            "<ipython-input-3-bfa305ef1fdd>:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_base[['Area P1', 'Area P2', 'Area P3','Area P4']] = df_base['Área'].apply(lambda x: pd.Series(split_competencies(x)))\n",
            "<ipython-input-3-bfa305ef1fdd>:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_base[['Area P1', 'Area P2', 'Area P3','Area P4']] = df_base['Área'].apply(lambda x: pd.Series(split_competencies(x)))\n",
            "<ipython-input-3-bfa305ef1fdd>:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_base[['Area P1', 'Area P2', 'Area P3','Area P4']] = df_base['Área'].apply(lambda x: pd.Series(split_competencies(x)))\n",
            "<ipython-input-3-bfa305ef1fdd>:100: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_base[['Area P1', 'Area P2', 'Area P3','Area P4']] = df_base['Área'].apply(lambda x: pd.Series(split_competencies(x)))\n",
            "<ipython-input-3-bfa305ef1fdd>:101: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_base['Area P1'] = df_base['Area P1'].str.upper()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Monitoring Procesado ....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-bfa305ef1fdd>:120: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_estructura_base['Fecha de inicio de relación laboral'] = pd.to_datetime(df_estructura_base['Fecha de inicio de relación laboral'], errors='coerce').dt.strftime('%d/%m/%Y')\n",
            "<ipython-input-3-bfa305ef1fdd>:121: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_estructura_base.rename(columns={'Nombre.1': 'Nombre'},inplace=True)\n",
            "<ipython-input-3-bfa305ef1fdd>:137: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_estructura_base_dig['Fecha de inicio de relación laboral'] = pd.to_datetime(df_estructura_dig['Fecha de inicio de relación laboral'], errors='coerce').dt.strftime('%d/%m/%Y')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estructura Tiendas Procesado ....\n",
            "Estructura Digital Procesado ....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-bfa305ef1fdd>:161: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_gorgos_base['Tiendas']=df_gorgos_base['Tiendas'].str.strip()\n",
            "<ipython-input-3-bfa305ef1fdd>:162: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_gorgos_base['Tienda M']=df_gorgos_base['Tiendas'].str.upper()\n",
            "<ipython-input-3-bfa305ef1fdd>:163: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_gorgos_base.drop_duplicates(inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame exported to: /content/drive/MyDrive/SPSA/Prueba Eval Desempeño/Outputs/output_2025-01-31.xlsx\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import sys\n",
        "\n",
        "def split_competencies(competencies_string):\n",
        "  if pd.isna(competencies_string):\n",
        "    return [], [], [], []\n",
        "  competencies = competencies_string.split(' -')\n",
        "  #print(competencies)\n",
        "  if len(competencies) == 4:\n",
        "      return competencies[0].strip(), competencies[1].strip(), competencies[2].strip(), competencies[3].strip()\n",
        "  elif len(competencies) == 3:\n",
        "      return competencies[0].strip(), competencies[1].strip(), competencies[2].strip(), ''\n",
        "  elif len(competencies) == 2:\n",
        "      return competencies[0].strip(), competencies[1].strip(), '',''\n",
        "  elif len(competencies) == 1:\n",
        "    return competencies[0].strip(), '', '',''\n",
        "  else:\n",
        "      return '', '', '',''\n",
        "\n",
        "def Buscar_Archivos(folder_path):\n",
        "  drive.mount('/content/drive')\n",
        "  file_estructura=''\n",
        "  file_evalMoni=''\n",
        "  file_closurvey=''\n",
        "  file_estrdig=''\n",
        "  file_gorgos=''\n",
        "\n",
        "  if os.path.exists(folder_path):\n",
        "    files = os.listdir(folder_path)\n",
        "    print(\"Archivos en la carpeta:\")\n",
        "    for file in files:\n",
        "      if file.startswith('6.- Estructura de personal'):\n",
        "        file_estructura = file\n",
        "        print(file_estructura)\n",
        "      elif file.startswith('evaluation_monitoring'):\n",
        "        file_evalMoni=file\n",
        "        print(file_evalMoni)\n",
        "      elif file.startswith('closing_survey_monitoring'):\n",
        "        file_closurvey=file\n",
        "        print(file_closurvey)\n",
        "      elif file.startswith('7.- Estructura de personal'):\n",
        "        file_estrdig=file\n",
        "        print(file_estrdig)\n",
        "      elif file.startswith('Base GOR'):\n",
        "        file_gorgos = file\n",
        "        print(file_gorgos)\n",
        "  else:\n",
        "    print(f\"La carpeta '{folder_path}' no existe.\")\n",
        "  return file_estructura, file_evalMoni, file_closurvey, file_estrdig, file_gorgos,[file_estructura, file_evalMoni, file_closurvey, file_estrdig, file_gorgos]\n",
        "#Busqueda de archivos\n",
        "\n",
        "def RealizarBackup(folder_path,folder_path_hist,files_to_backup):\n",
        "  today = datetime.today().strftime('%Y-%m-%d')\n",
        "  backup_folder = os.path.join(folder_path_hist, today)\n",
        "\n",
        "  if not os.path.exists(backup_folder):\n",
        "      os.makedirs(backup_folder)\n",
        "      print(f\"Carpeta '{backup_folder}' creada exitosamente.\")\n",
        "  else:\n",
        "      print(f\"La carpeta '{backup_folder}' ya existe.\")\n",
        "\n",
        "  for file in files_to_backup:\n",
        "    source_file = os.path.join(folder_path, file)\n",
        "    destination_file = os.path.join(backup_folder, file)\n",
        "\n",
        "    if os.path.exists(source_file):\n",
        "      try:\n",
        "        shutil.copy2(source_file, destination_file)\n",
        "        print(f\"Archivo '{file}' copiado a '{backup_folder}'\")\n",
        "      except Exception as e:\n",
        "        print(f\"Error al copiar '{file}': {e}\")\n",
        "    else:\n",
        "      print(f\"Archivo '{file}' no encontrado en la carpeta de origen.\")\n",
        "\n",
        "\n",
        "def CargarEvalMonitoring(file_evalMoni,folder_path):\n",
        "\n",
        "  file_name = file_evalMoni\n",
        "  file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "  if os.path.exists(file_path):\n",
        "    try:\n",
        "      df = pd.read_excel(file_path, sheet_name='Listado de Evaluaciones', usecols='A:T', skiprows=7, dtype=str)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al leer el archivo: {e}\")\n",
        "  else:\n",
        "    print(f\"El archivo '{file_name}' no existe en la carpeta especificada.\")\n",
        "\n",
        "  df = df.rename(columns={'Identifier.1': 'Identifier_Evaluador','Nombre.1': 'Nombre_Evaluador','Identifier.1': 'Identifier_Evaluador','Apellido.1': 'Apellido_Evaluador','Rut.1': 'Rut_Evaluador','Username.1': 'Username_Evaluador',\n",
        "                          'Email.1': 'Email_Evaluador','Área.1': 'Área_Evaluador','Cargo.1': 'Cargo_Evaluador'})\n",
        "  df = df.loc[df['Categoría']=='Evaluación del Jefe directo']\n",
        "  df_base = df[['Identifier', 'Nombre', 'Apellido', 'Rut','Username', 'Email', 'Área', 'Cargo', 'Jerarquía', 'Familia de competencias', 'Identifier_Evaluador', 'Nombre_Evaluador',\n",
        "        'Apellido_Evaluador', 'Rut_Evaluador', 'Username_Evaluador', 'Email_Evaluador', 'Área_Evaluador', 'Cargo_Evaluador']]\n",
        "  df_base.drop_duplicates(inplace=True)\n",
        "  df_base[['Area P1', 'Area P2', 'Area P3','Area P4']] = df_base['Área'].apply(lambda x: pd.Series(split_competencies(x)))\n",
        "  df_base['Area P1'] = df_base['Area P1'].str.upper()\n",
        "  df_clean = df_base.copy()\n",
        "  df_clean = df_clean[~df_clean['Familia de competencias'].isin(['decs-pva-31287','decs-admi-31287'])]\n",
        "  df_clean = df_clean[df_clean['Area P1'].isin(['MK','FRET','OPL','SPO','DF'])]\n",
        "  print(\"Evaluation Monitoring Procesado ....\")\n",
        "  return df_clean\n",
        "\n",
        "def CargaEstructuraTiendas(file_estructura,folder_path):\n",
        "  file_name = file_estructura\n",
        "  file_path = os.path.join(folder_path, file_name)\n",
        "  if os.path.exists(file_path):\n",
        "    try:\n",
        "      df_estructura = pd.read_excel(file_path, sheet_name='Sheet1', usecols='A:AG', skiprows=2,dtype=str)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al leer el archivo: {e}\")\n",
        "  else:\n",
        "    print(f\"El archivo '{file_name}' no existe en la carpeta especificada.\")\n",
        "\n",
        "  df_estructura_base = df_estructura[['Número de persona','Nombre de unidad de negocio','Número de documento de identidad principal','Nombre.1','Fecha de inicio de relación laboral']]\n",
        "  df_estructura_base['Fecha de inicio de relación laboral'] = pd.to_datetime(df_estructura_base['Fecha de inicio de relación laboral'], errors='coerce').dt.strftime('%d/%m/%Y')\n",
        "  df_estructura_base.rename(columns={'Nombre.1': 'Nombre'},inplace=True)\n",
        "  print(\"Estructura Tiendas Procesado ....\")\n",
        "  return df_estructura_base\n",
        "\n",
        "def CargaEstructuraDig(file_estrdig,folder_path):\n",
        "  file_name = file_estrdig\n",
        "  file_path = os.path.join(folder_path, file_name)\n",
        "  if os.path.exists(file_path):\n",
        "    try:\n",
        "      df_estructura_dig = pd.read_excel(file_path, sheet_name='Sheet1', usecols='A:AG', skiprows=2,dtype=str)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al leer el archivo: {e}\")\n",
        "  else:\n",
        "    print(f\"El archivo '{file_name}' no existe en la carpeta especificada.\")\n",
        "\n",
        "  df_estructura_base_dig = df_estructura_dig[['Número de persona','Nombre de unidad de negocio','Número de documento de identidad principal','Nombre','Fecha de inicio de relación laboral']]\n",
        "  df_estructura_base_dig['Fecha de inicio de relación laboral'] = pd.to_datetime(df_estructura_dig['Fecha de inicio de relación laboral'], errors='coerce').dt.strftime('%d/%m/%Y')\n",
        "  print(\"Estructura Digital Procesado ....\")\n",
        "  return df_estructura_base_dig\n",
        "\n",
        "def ConsolEstructura(df_estructura_base,df_estructura_base_dig):\n",
        "  df_estructura_consol = pd.concat([df_estructura_base, df_estructura_base_dig], ignore_index=True)\n",
        "  df_estructura_consol = df_estructura_consol.loc[~df_estructura_consol['Número de persona'].isna()]\n",
        "  df_estructura_consol['Nombre'] = df_estructura_consol['Nombre'].str.title()\n",
        "  df_estructura_consol.rename(columns={'Nombre':'Nombre Completo' },inplace=True)\n",
        "  return df_estructura_consol\n",
        "\n",
        "def CargaGorgos(file_gorgos,folder_path):\n",
        "  file_name = file_gorgos\n",
        "  file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "  if os.path.exists(file_path):\n",
        "    try:\n",
        "      df_gorgos = pd.read_excel(file_path, sheet_name='Tiendas', usecols='A:F', skiprows=0,dtype=str)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al leer el archivo: {e}\")\n",
        "  else:\n",
        "    print(f\"El archivo '{file_name}' no existe en la carpeta especificada.\")\n",
        "\n",
        "  df_gorgos_base = df_gorgos[['Tiendas','GOR','GOS']]\n",
        "  df_gorgos_base['Tiendas']=df_gorgos_base['Tiendas'].str.strip()\n",
        "  df_gorgos_base['Tienda M']=df_gorgos_base['Tiendas'].str.upper()\n",
        "  df_gorgos_base.drop_duplicates(inplace=True)\n",
        "  return df_gorgos_base\n",
        "\n",
        "def CargaRespuestaEvalMoni(file_evalMoni,folder_path):\n",
        "  file_name = file_evalMoni\n",
        "  file_path = os.path.join(folder_path, file_name)\n",
        "  import pandas as pd\n",
        "  if os.path.exists(file_path):\n",
        "    try:\n",
        "      df_notas_1_4 = pd.read_excel(file_path, sheet_name='Evaluados', usecols='A:AS', skiprows=7, dtype=str)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al leer el archivo: {e}\")\n",
        "  else:\n",
        "    print(f\"El archivo '{file_name}' no existe en la carpeta especificada.\")\n",
        "\n",
        "  df_notas_1_4.rename(columns={'Asignadas':'Asignadas EJD','Completadas':'Completadas EJD','En progreso':'En progreso EJD','No comenzado':'No comenzado EJD','% de avance':'% de avance EJD','Ponderación':'Ponderación EJD',\n",
        "                      'Asignadas.1':'Asignadas EAL','Completadas.1':'Completadas EAL','En progreso.1':'En progreso EAL','No comenzado.1':'No comenzado EAL','% de avance.1':'% de avance EAL','Ponderación.1':'Ponderación EAL',\n",
        "                      'Asignadas.2':'Asignadas PCI','Completadas.2':'Completadas PCI','En progreso.2':'En progreso PCI','No comenzado.2':'No comenzado PCI','% de avance.2':'% de avance PCI','Ponderación.2':'Ponderación PCI',\n",
        "                      'Asignadas.3':'Asignadas EME','Completadas.3':'Completadas EME','En progreso.3':'En progreso EME','No comenzado.3':'No comenzado EME','% de avance.3':'% de avance EME','Ponderación.3':'Ponderación EME',\n",
        "                      'Asignadas.4':'Asignadas EMC','Completadas.4':'Completadas EMC','En progreso.4':'En progreso EMC','No comenzado.4':'No comenzado EMC','% de avance.4':'% de avance EMC','Ponderación.4':'Ponderación EMC',\n",
        "                      'Estado':'Estado AUT','Ponderación.5':'Ponderación AUT',\n",
        "                      'Asignadas.5':'Asignadas FED','Completadas.5':'Completadas FED','% de avance.5':'% de avance FED'\n",
        "                      },inplace=True)\n",
        "  return df_notas_1_4\n",
        "\n",
        "def CargaClosingSurvey(file_closurvey,folder_path):\n",
        "  file_name = file_closurvey\n",
        "  file_path = os.path.join(folder_path, file_name)\n",
        "  import pandas as pd\n",
        "  if os.path.exists(file_path):\n",
        "    try:\n",
        "      df_closurv = pd.read_excel(file_path, sheet_name='Feedbacks', usecols='A:I', skiprows=7, dtype=str)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al leer el archivo: {e}\")\n",
        "  else:\n",
        "    print(f\"El archivo '{file_name}' no existe en la carpeta especificada.\")\n",
        "  return df_closurv\n",
        "\n",
        "def DataProcessing(df_evalMonitoring,df_estructura_consol,df_gorgos_base,df_notas_1_4,df_closurv):\n",
        "  df_clean_2 = pd.merge(df_evalMonitoring, df_estructura_consol[['Número de persona','Nombre Completo','Fecha de inicio de relación laboral']], left_on='Identifier', right_on='Número de persona', how='left')\n",
        "  df_clean_2.drop(columns=['Número de persona'], inplace=True)\n",
        "\n",
        "  df_estructura_base_2 = df_estructura_consol.copy()\n",
        "  df_estructura_base_2.rename(columns={'Fecha de inicio de relación laboral':'Fecha de inicio de relación laboral Evaluador' },inplace=True)\n",
        "  df_clean_2 = pd.merge(df_clean_2, df_estructura_base_2[['Número de persona', 'Fecha de inicio de relación laboral Evaluador']], left_on='Identifier_Evaluador', right_on='Número de persona', how='left')\n",
        "  df_clean_2.drop(columns=['Número de persona'], inplace=True)\n",
        "  df_clean_2.loc[df_clean_2['Area P4']!='','Area P3'] = df_clean_2.loc[df_clean_2['Area P4']!='','Area P3'] +' '+df_clean_2.loc[df_clean_2['Area P4']!='','Area P4']\n",
        "  df_clean_2.rename(columns={'Area P1':'Formato','Area P2':'Tienda','Area P3':'Seccion' },inplace=True)\n",
        "  df_clean_2['Evaluado Activo Cesado'] = np.where(df_clean_2['Fecha de inicio de relación laboral'].isnull(), 'Cesado', 'Activo')\n",
        "  df_clean_2['Evaluador Activo Cesado'] = np.where(df_clean_2['Fecha de inicio de relación laboral Evaluador'].isnull(), 'Cesado', 'Activo')\n",
        "  df_clean_2.drop_duplicates(inplace=True)\n",
        "\n",
        "  df_clean_3 = pd.merge(df_clean_2, df_notas_1_4[['Identifier','% de avance EJD','Estado AUT','% de avance EME','% de avance FED']], left_on='Identifier', right_on='Identifier', how='left')\n",
        "  df_clean_4 = pd.merge(df_clean_3, df_closurv[['Identificador','Estado encuesta']], left_on='Identifier', right_on='Identificador', how='left')\n",
        "  df_clean_4.drop(columns=['Identificador'], inplace=True)\n",
        "\n",
        "  #Autoevaluación\n",
        "  df_clean_4['Autoevaluación Status'] = 'N/A'\n",
        "  df_clean_4['Autoevaluación %'] = '0%'\n",
        "  df_clean_4['Autoevaluación Den'] = 0\n",
        "  df_clean_4['Autoevaluación Num'] = 0\n",
        "  df_clean_4.loc[df_clean_4['Estado AUT']==' - ','Autoevaluación Status'] = 'NO APLICA'\n",
        "  df_clean_4.loc[df_clean_4['Autoevaluación Status']=='N/A','Autoevaluación Status'] = df_clean_4.loc[df_clean_4['Autoevaluación Status']=='N/A','Estado AUT']\n",
        "  df_clean_4.loc[df_clean_4['Autoevaluación Status']=='NO APLICA','Autoevaluación %'] = 'NO APLICA'\n",
        "  df_clean_4.loc[df_clean_4['Autoevaluación Status']!='NO APLICA','Autoevaluación Den'] = 1\n",
        "  df_clean_4.loc[df_clean_4['Autoevaluación Status']=='Finalizado','Autoevaluación %'] = '100%'\n",
        "  df_clean_4.loc[df_clean_4['Autoevaluación Status']=='Finalizado','Autoevaluación Num'] = 1\n",
        "  ## Evaluacion Lider\n",
        "  df_clean_4['Evaluación del Líder Status'] = 'No comenzado'\n",
        "  df_clean_4['Evaluación del Líder Den'] = 1\n",
        "  df_clean_4['Evaluación del Líder Num'] = 0\n",
        "  df_clean_4.loc[df_clean_4['% de avance EJD']=='100%','Evaluación del Líder Status'] = 'Finalizado'\n",
        "  df_clean_4['Evaluación del Líder %'] = df_clean_4['% de avance EJD']\n",
        "  df_clean_4.loc[df_clean_4['Evaluación del Líder Status']=='Finalizado','Evaluación del Líder Num'] = 1\n",
        "  #Matricial\n",
        "  df_clean_4['Matricial Status'] = 'No comenzado'\n",
        "  df_clean_4['Matricial %'] = '0%'\n",
        "  df_clean_4['Matricial Den'] = 0\n",
        "  df_clean_4['Matricial Num'] = 0\n",
        "  df_clean_4.loc[df_clean_4['% de avance EME']==' - ','Matricial Status'] = 'NO APLICA'\n",
        "  df_clean_4.loc[df_clean_4['% de avance EME']=='100%','Matricial Status'] = 'Finalizado'\n",
        "  df_clean_4.loc[df_clean_4['Matricial Status']=='NO APLICA','Matricial %'] = 'NO APLICA'\n",
        "  df_clean_4.loc[df_clean_4['Matricial Status']!='NO APLICA','Matricial Den'] = 1\n",
        "  df_clean_4.loc[df_clean_4['Matricial Status']=='Finalizado','Matricial %'] = '100%'\n",
        "  df_clean_4.loc[df_clean_4['Matricial Status']=='Finalizado','Matricial Num'] = 1\n",
        "  ## Feedback\n",
        "  df_clean_4['Feedback Status'] = 'No comenzado'\n",
        "  df_clean_4['Feedback Den'] = 1\n",
        "  df_clean_4['Feedback Num'] = 0\n",
        "  df_clean_4.loc[df_clean_4['% de avance FED']=='100%','Feedback Status'] = 'Finalizado'\n",
        "  df_clean_4['Feedback %'] = df_clean_4['% de avance FED']\n",
        "  df_clean_4.loc[df_clean_4['Feedback Status']=='Finalizado','Feedback Num'] = 1\n",
        "  ## Encuesta\n",
        "  df_clean_4['Encuesta %'] ='0%'\n",
        "  df_clean_4['Encuesta Status'] = df_clean_4['Estado encuesta']\n",
        "  df_clean_4.loc[df_clean_4['Estado encuesta']=='Finalizado','Encuesta %'] = '100%'\n",
        "  df_clean_4['Encuesta Den'] = 1\n",
        "  df_clean_4['Encuesta Num'] = 0\n",
        "  df_clean_4.loc[df_clean_4['Estado encuesta']=='Finalizado','Encuesta Num'] = 1\n",
        "\n",
        "  df_clean_4['Den Avance Global'] = df_clean_4['Autoevaluación Den']+df_clean_4['Evaluación del Líder Den']+df_clean_4['Matricial Den']+df_clean_4['Feedback Den']+df_clean_4['Encuesta Den']\n",
        "  df_clean_4['Num Avance Global'] = df_clean_4['Autoevaluación Num']+df_clean_4['Evaluación del Líder Num']+df_clean_4['Matricial Num']+df_clean_4['Feedback Num']+df_clean_4['Encuesta Num']\n",
        "  df_clean_4['%Avance Global'] = np.where(df_clean_4['Num Avance Global']/df_clean_4['Den Avance Global']==1,1,0)#*100\n",
        "  df_clean_4['Status Avance Global'] = np.where(df_clean_4['%Avance Global']==1,'Finalizado','Pendiente')#*100\n",
        "\n",
        "  df_clean_4['Tienda M']=df_clean_4['Tienda'].str.upper()\n",
        "  df_clean_4['Tienda M']=df_clean_4['Tienda M'].str.strip()\n",
        "\n",
        "  df_clean_5 = pd.merge(df_clean_4, df_gorgos_base, left_on='Tienda M', right_on='Tienda M', how='left')\n",
        "  list_cabecera_fin =['Identifier', 'Nombre', 'Apellido', 'Rut', 'Username','Nombre Completo','Email', 'Área',\n",
        "        'Cargo', 'Jerarquía', 'Familia de competencias', 'Identifier_Evaluador',\n",
        "        'Nombre_Evaluador', 'Apellido_Evaluador', 'Rut_Evaluador',\n",
        "        'Username_Evaluador', 'Email_Evaluador', 'Área_Evaluador',\n",
        "        'Cargo_Evaluador', 'Formato', 'Tienda', 'Seccion','Fecha de inicio de relación laboral',\n",
        "        'Fecha de inicio de relación laboral Evaluador', 'Evaluado Activo Cesado',\n",
        "        'Evaluador Activo Cesado','GOR','GOS', 'Autoevaluación Status','Evaluación del Líder Status','Matricial Status','Feedback Status','Encuesta Status',\n",
        "        'Autoevaluación %','Evaluación del Líder %','Matricial %','Feedback %','Encuesta %',\n",
        "        'Den Avance Global','Num Avance Global','%Avance Global','Status Avance Global']\n",
        "  df_clean_final = df_clean_5[list_cabecera_fin]\n",
        "  return df_clean_final\n",
        "\n",
        "def GuardarExcel(df_clean_final,folder_ouput):\n",
        "  today = datetime.today().strftime('%Y-%m-%d')\n",
        "  output_file_path = f'{folder_ouput}/output_{today}.xlsx'\n",
        "  df_clean_final.to_excel(output_file_path, index=False, engine='openpyxl')\n",
        "  print(f\"DataFrame exported to: {output_file_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  folder_path = '/content/drive/MyDrive/SPSA/Prueba Eval Desempeño/Inputs'\n",
        "  folder_path_hist = '/content/drive/MyDrive/SPSA/Prueba Eval Desempeño/Inputs/Inputs Historico'\n",
        "  folder_ouput = '/content/drive/MyDrive/SPSA/Prueba Eval Desempeño/Outputs'\n",
        "\n",
        "  file_estructura, file_evalMoni, file_closurvey, file_estrdig, file_gorgos, list_bkp = Buscar_Archivos(folder_path)\n",
        "  RealizarBackup(folder_path,folder_path_hist,list_bkp)\n",
        "  df_evalMonitoring = CargarEvalMonitoring(file_evalMoni,folder_path)\n",
        "  df_estructuraTienda = CargaEstructuraTiendas(file_estructura,folder_path)\n",
        "  df_estructura_dig = CargaEstructuraDig(file_estrdig,folder_path)\n",
        "  df_estructura_consol = ConsolEstructura(df_estructuraTienda,df_estructura_dig)\n",
        "  df_gorgos_base = CargaGorgos(file_gorgos,folder_path)\n",
        "  df_notas_1_4 = CargaRespuestaEvalMoni(file_evalMoni,folder_path)\n",
        "  df_closurv = CargaClosingSurvey(file_closurvey,folder_path)\n",
        "  df_final = DataProcessing(df_evalMonitoring,df_estructura_consol,df_gorgos_base,df_notas_1_4,df_closurv)\n",
        "  GuardarExcel(df_final,folder_ouput)\n"
      ]
    }
  ]
}